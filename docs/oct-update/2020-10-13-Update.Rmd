---
title: Update
author: John Best
date: October 13, 2020
---

```{r setup, include = FALSE}
library(tidyverse)
devtools::load_all("~/dev/spatq")

knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

$$\renewcommand{\vec}[1]{\boldsymbol{#1}}$$

# Model review

The proposed model uses a zero-inflated log-normal observation likelihood with a
Poisson link function. The linear predictors for numbers density, $n$, and
weight per group, $w$, are

$$\log \vec{n} =
  \vec{X}_n\vec{\beta}_n + \vec{A}_\omega\vec{\omega}_n + \vec{A}_{\epsilon}\vec{\epsilon}_n +
  \vec{Q}_n\vec{\lambda}_n + \vec{A}_{\phi}\vec{\phi}_n + \vec{A}_{\psi}\vec{\psi}_n$$
$$\log \vec{w} =
  \vec{X}_w\vec{\beta}_w + \vec{A}_\omega\vec{\omega}_w + \vec{A}_{\epsilon}\vec{\epsilon}_w +
  \vec{Q}_w\vec{\lambda}_w + \vec{A}_{\phi}\vec{\phi}_w + \vec{A}_{\psi}\vec{\psi}_w$$
  
Where each linear predictor may include:

- $\vec{X}_{\cdot}\vec{\beta}_\cdot$: abundance fixed effects (e.g. year)
- $\vec{A}_\omega\vec{\omega}_\cdot$: abundance spatial effects
- $\vec{A}_{\epsilon}\vec{\epsilon}_\cdot$: abundance spatiotemporal effects
- $\vec{Q}_\cdot\vec{\lambda}_\cdot$: catchability fixed effects (e.g. vessel/fleet)
- $\vec{A}_{\phi}\vec{\phi}_\cdot$: catchability spatial effects
- $\vec{A}_{\psi}\vec{\psi}_\cdot$: catchability spatiotemporal effects

The spatial and spatiotemporal effects parameter vectors take multivariate
normal distributions, each of which depends on independent parameters $\kappa$ and
$\tau$. These parameters can be difficult to estimate. In two dimensions and
fixing the Mat√©rn smoothness parameter $\nu$ to $1$,

$$\kappa = \frac{\sqrt{8}}{\rho}$$

where $\rho$ is the distance at which correlation drops to roughly $0.1$. This
parameter cannot be consistently estimated under in-fill asymptotics (adding
additional observations within a fixed domain). The parameter $\tau$ on the
other hand *can* be consistently estimated under in-fill asymptotics[^1]. For
$\nu = 1$, $\tau$ is the ratio of the marginal standard deviation $\sigma$ to the
correlation range,

$$\tau = 4 \sqrt{2\pi} \frac{\sigma}{\rho}.$$

The intuition here is that in a fixed domain, a field with short correlation
range and small marginal variance will generate similar realizations to a field
with long correlation range and large marginal variance. In a model that
includes all the specified spatial and spatiotemporal effects, eight $\kappa$
and eight $\tau$ parameters must be estimated.

[^1]: Zhang. 2008. *Inconsistent estimation and asymptotically equal interpolations in model-based geostatistics*. J Am Stat Soc. [https://doi.org/10/b6ttjp](https://doi.org/10/b6ttjp)

# Progress

## Bugs

At the beginning of the summer I was struggling to fit models with spatial and
spatiotemporal random fields for abundance, i.e. to be on par with the basic
functionality of VAST. I discovered and fixed two major bugs in my TMB model.
One covariance parameter was mis-indexed so that the parameter was shared by two
random fields. Another parameter was not used by the model at all. This fix was
straightforward once discovered.

The second was a misunderstanding of how the Eigen library can reshape a
two-dimensional matrix into a vector. My spatiotemporal random fields were
originally two-dimensional matrices, with mesh nodes as rows and years as
columns. This was based on my understanding of the facilities in TMB for
separable spatiotemporal random fields and made calculating the final indices of
abundance simpler. It also simplified the indexing required for calculating the
final index of abundance. However, I still needed a single vector in order to
project the field to the observation locations and calculate the linear
predictor. The method that I used to try to reshape the parameter matrix into a
vector (`matrix.value()`) only returned the first value in the matrix rather
than a vector. I rewrote this code to represent each spatiotemporal field as a
vector.

## Fitting data generated by the estimation model

The TMB model includes the ability to simulate observations from the estimation
model given a set of parameter values and observation locations. This simulated
data was used to test the model's ability to recover generative parameters. The
model did well recovering parameter values, with some important caveats. The
primary issue is that the optimizer often gets stuck in areas of parameter space
where the Hessian is not positive definite. This can indicate that the parameter
values are at a saddle rather than a maximum, or be the result of numerical
issues when calculating the eigenvalues of a poorly conditioned matrix. The
optimizer consistently finds parameter values with a positive definite Hessian
when spatial and spatiotemporal abundance and spatial catchability are estimated,
along with their $\kappa$ and $\tau$ parameters. Including spatiotemporal
catchability usually results in a non-positive definite Hessian. It is also
important to note that parameter values with positive definite Hessians are most
often found when the initial parameter values are close to the final
values. In the case of data generated from the estimation model, the generative
values were used to initialize the optimization procedure. I take this as
evidence that the major bugs have been resolved and the remaining challenges
will mostly be related to finding appropriate starting values and ensuring the
optimizer reaches a minimum with a positive definite Hessian.

To demonstrate this, ten data sets were generated from the estimation model.
These were then fit using the generative values as initial values for the
optimizer. Of the ten, nine reached parameter values with a positive definite
Hessian. The generative values for the year effects are recovered well, without
obvious bias.

```{r gen-recover-plot-setup}
em_sims <- readRDS("oct-update-em-fits.RData")
max_T <- 5

### Extract results of simulation study
pd_hess <- map_lgl(em_sims, pluck, "pdHess")
fix_pars <- map(em_sims, pluck, "par.fixed")
rand_pars <- map(em_sims, pluck, "par.random")

## Define generative values
## Initialize like this for Helmert contrasts
genvals <- list()
genvals$beta_n <- c(0.5, rep(0, max_T - 1))
genvals$beta_w <- c(-10, rep(0, max_T - 1))
genvals$lambda_n <- 0.4
genvals$lambda_w <- 1.6
## Give spatial parameters a 60-unit range and spatiotemporal a 30-unit range
genvals$log_kappa <- c(log(pars_kappa(60)), log(pars_kappa(60)),
                       log(pars_kappa(30)), log(pars_kappa(30)),
                       log(pars_kappa(60)), log(pars_kappa(60)))
genvals$log_tau <- rep(3, 6)
genvals$log_sigma <- 0
df_ref <- tibble(par = make.unique(names(em_sims[[1]]$par.fixed)),
                 val = unlist(genvals))

n_par <- length(em_sims[[1]]$par.fixed)
## df_ref <- tibble(par = make.unique(names(em_sims[[1]]$par.fixed)),
##                  val = obj_sim$par)
df_fp <- map(fix_pars, ~ tibble(par = make.unique(names(.x)), val = .x)) %>%
  bind_rows() %>%
  mutate(repl = rep(1:10, each = n_par)) %>%
  left_join(tibble(repl = 1:10, pd_hess = pd_hess), by = "repl")
```

```{r beta-plot}
df_fp %>%
  filter(grepl("beta", par)) %>%
  ggplot(aes(x = val, fill = pd_hess, color = pd_hess)) +
  facet_wrap(~ par, scales = "free_x", ncol = 2, dir = "v") +
  geom_point(y = 0, size = 3, alpha = 0.8) +
  geom_vline(aes(xintercept = val),
             data = filter(df_ref, grepl("beta", par))) +
  coord_cartesian(ylim = c(-1, 1)) +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        axis.title.x = element_blank(),
        legend.position = "bottom")
```

Estimates of the parameters controlling the Gaussian random fields show a large
amount of variation around the generative values. Pairs of rows below control
spatial abundance, spatiotemporal abundance, and spatial catchability. Note that
the fit with a non-positive definite Hessian includes values for `log_kappa` and
`log_tau` far from the generative values.

```{r hyperpar-plot}
df_fp %>%
  filter(grepl("kappa|tau", par)) %>%
  ggplot(aes(x = val, fill = pd_hess, color = pd_hess)) +
  facet_wrap(~ par, scales = "free", ncol = 2, dir = "v") +
  geom_point(y = 0, size = 3, alpha = 0.8) +
  geom_vline(aes(xintercept = val),
             data = filter(df_ref, grepl("kappa|tau", par))) +
  coord_cartesian(ylim = c(-1, 1)) +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        axis.title.x = element_blank(),
        legend.position = 'bottom')
```

## Where are the negative eigenvalues coming from?

```{r neg_eigs}
em_hess <- readRDS("oct-update-hess.RData")
ne1 <- nulleigs(em_hess[[1]], abstol = 0)
```

Looking more closely at the replicate with a non-positive definite Hessian, it
is possible to see which parameters are most strongly associated with the small
or negative eigenvalues by looking at the largest components of the eigenvectors
associated with those eigenvalues. In this case one of the eigenvalues of this
Hessian is negative. This eigenvalue is primarily associated with the
parameters controlling the spatial catchability random field.

```{r}
ord <- order(abs(ne1$vectors), decreasing = TRUE)
knitr::kable(
         tibble(`Parameter` = ne1$sortedpars,
                `Eigenvector loading` = ne1$vectors[ord])[1:5, ])
```

This is consistent with the extreme values shown above for these parameters in
this fit. It is also consistent with the very large off-diagonal correlations
between each pair of $\kappa$ and $\tau$ parameters in the parameter correlation
matrix (with one missing row/column). 

```{r}
fixpar_corrplot(em_sims[[1]])
```

This is also present in fits where the Hessian is positive definite. 

```{r}
fixpar_corrplot(em_sims[[2]])
```

**Note** I have slightly reparameterized the model since these fits, with the
result that the off-diagonal correlations between each pair of $\kappa$ and
$\tau$ are positive rather than negative, but of comparable magnitude.

## Example random fields

```{r}
sims <- readRDS("oct-update-sims.RData")
```

Using a fit with a positive definite Hessian, I can provide some examples of the
empirical Bayes estimates of the random fields. The estimated spatial abundance
process, $\vec{\hat{\omega}}$, and the generative field $\vec{\omega}$
fitted 

```{r}
plot_field(em_sims[[2]]$par.random, sims[[2]], par_regex = "omega", colorbar = TRUE)
```

The estimated spatiotemporal abundance fields $\vec{\hat{\epsilon}}$ and corresponding
generative field $\vec{\epsilon}$.

```{r}
plot_field(em_sims[[2]]$par.random, sims[[2]], par_regex = "epsilon", colorbar = TRUE)
```

And the estimated spatial catchability $\vec{\hat{\phi}}$ and generative
$\vec{\phi}$ fields.


```{r}
plot_field(em_sims[[2]]$par.random, sims[[2]], par_regex = "phi", colorbar = TRUE)
```

The empirical Bayes estimates of the random fields appear to capture the spatial
structure of the generative field.

# Next steps

At this point I would like to focus on fitting models with spatial and
spatiotemporal abundance random fields and spatial catchability random fields. I
may consider including spatiotemporal catchability random fields later, but I
would like to push forward in the direction that seems most promising. Once I
consistently find optima with positive definite Hessians, I will run a large
number of replicates of the operating model and get initial metrics for index
improvement when spatial catchability is included. As previously discussed, the
metrics will address bias, error, and coverage of the estimated indices of
abundance.

## Finding appropriate initial values

When fitting data simulated directly from the estimation model, the generative
parameter values can be used as initial values for optimization. Obviously this
is not possible with real-life data, nor is it feasible for data generated from
the operating model, which uses a different parameterization. One way to deal
with this is to implement a phasing scheme, where model components are added
sequentially. In this case I am experimenting with estimating fixed effects,
then including spatial abundance, spatiotemporal abundance, and spatial
catchability. Further work will establish whether this is sufficient for fitting
data from the operating model, or if additional work should be done, e.g. taking
Newton steps between phases as in Jim's `TMBhelper::fit_tmb` functions.

## Regularizing random field parameter estimates

Including a penalty term to keep the correlation range and marginal standard
deviation under control can stabilize the estimation of these parameters. This
may be necessary here where it is not in e.g. VAST due to the number of random
fields being estimated and the fact that the catchability fields are estimated
using a strict subset of the data used for the abundance random fields. This is
likely exacerbated by 

The penalized complexity framework aims to specify prior distributions for
Bayesian analysis that shrink models toward simpler "base" models[^2]. In the
case of the Gaussian random fields used here, penalized complexity priors can be
used as penalty terms for the $\kappa$ and $\tau$ parameters. This prior/penalty
tends to shrink the Gaussian random field toward having an infinite correlation
range and zero variance, i.e. a constant[^3]. These priors are intuitively
parameterized, so that for some correlation range $\rho_{0}$ and tail
probability $\alpha_{1}$,

$$\Pr(\rho < \rho_{0}) = \alpha_{1}.$$

Similarly, for a marginal standard deviation $\sigma_{0}$ and tail probability
$\alpha_{2}$,

$$\Pr(\sigma > \sigma_{0} \mid \rho) = \alpha_{2}.$$

The joint prior can be calculated in terms of $\kappa$ and $\tau$, even when it
is parameterized in terms of $\rho$ and $\sigma$. Attempts to use this prior as
a penalty term have been promising when fitting data from the operating model.
Fits result in positive definite Hessians, but more work is needed to validate
the approach using data generated from the estimation model, and to choose
appropriate values of $\rho_{0}$ and $\sigma_{0}$ for each estimated Gaussian
random field. It may also be possible to apply a penalty to only the $\kappa$
parameters.

[^2]: Simpson et al., 2017. *Penalising model component complexity: a principled, practical approach to constructing priors*. J Am Stat Assoc. [https://doi.org/10.1214/16-STS576](https://doi.org/10.1214/16-STS576)

[^3]: Fuglstad et al., 2018. *Constructing priors that penalize the complexity of Gaussian random fields*. J Am Stat Assoc. [https://doi.org/10/ggkqqb](https://doi.org/10/ggkqqb) 
